{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "we advise you to read understand_masks before going through this notebook"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from deepctr.feature_column import SparseFeat, VarLenSparseFeat, DenseFeat, get_feature_names, build_input_features\n",
    "from deepctr.models.sequence.attentional_pooling import AttentionalPooling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_xy_fd(hash_flag=False):\n",
    "    constant_feature_columns = [SparseFeat('user', 5, embedding_dim=10, use_hash=hash_flag),\n",
    "                       SparseFeat('gender', 2, embedding_dim=4, use_hash=hash_flag),\n",
    "                       # SparseFeat('item_id', 3 + 1, embedding_dim=8, use_hash=hash_flag),\n",
    "                       # SparseFeat('cate_id', 2 + 1, embedding_dim=4, use_hash=hash_flag),\n",
    "                       DenseFeat('pay_score', 3)]\n",
    "\n",
    "    behavior_feature_columns = [\n",
    "        VarLenSparseFeat(SparseFeat('hist_item_id', vocabulary_size=5 + 1, embedding_dim=8, embedding_name='item_id'),\n",
    "                         maxlen=4, length_name=\"seq_length\"),\n",
    "        VarLenSparseFeat(SparseFeat('hist_cate_id', 5 + 1, embedding_dim=4, embedding_name='cate_id'),\n",
    "                         maxlen=4, length_name=\"seq_length\"),\n",
    "        DenseFeat('hist_dense1', 4),\n",
    "        DenseFeat('hist_dense2', 4)]\n",
    "\n",
    "    behavior_sparse_indicator = [\"item_id\", \"cate_id\"]\n",
    "    uid = np.array([0, 1, 2, 3, 4])\n",
    "    ugender = np.array([0, 0, 1, 1, 0])\n",
    "    # iid = np.array([1, 2, 3])  # 0 is mask value\n",
    "    # cate_id = np.array([1, 2, 2])  # 0 is mask value\n",
    "    score = np.array([[0.1, 0.2, 0.3], [0.2, 0.2, 0.3], [0.3, 0.2, 0.3],\n",
    "                      [0.4, 0.2, 0.3], [0.5, 0.2, 0.3]])\n",
    "\n",
    "    hist_iid = np.array([[1, 2, 3, 0], [2, 2, 3, 0], [3, 2, 0, 0],\n",
    "                         [4, 5, 0, 0], [5, 1, 2, 0]])\n",
    "    hist_cate_id = np.array([[1, 2, 2, 0], [2, 2, 2, 0], [3, 2, 0, 0],\n",
    "                             [4, 2, 0, 0], [5, 2, 2, 0]])\n",
    "    dense1 = np.array([[0.5, 0.1, 0.2, 0], [0.7, 0.6, 0.3, 0], [0.3, 0.2, 0, 0],\n",
    "                       [0.1, 0.1, 0, 0], [0.2, 0.1, 0.2, 0]])\n",
    "    dense2 = np.array([[0.2, 0.2, 0.2, 0], [0.5, 0.1, 0.1, 0], [0.1, 0.2, 0, 0],\n",
    "                       [0.4, 0.2, 0, 0], [0.3, 0.1, 0.1, 0]])\n",
    "\n",
    "    behavior_length = np.array([3, 3, 2, 2, 3])\n",
    "\n",
    "    feature_dict = {'user': uid,\n",
    "                    'gender': ugender,\n",
    "                    # 'item_id': iid, 'cate_id': cate_id,\n",
    "                    'hist_item_id': hist_iid, 'hist_cate_id': hist_cate_id,\n",
    "                    'pay_score': score, \"seq_length\": behavior_length,\n",
    "                    'hist_dense1': dense1, 'hist_dense2': dense2}\n",
    "\n",
    "    x = {name: feature_dict[name] for name in get_feature_names(\n",
    "        constant_feature_columns + behavior_feature_columns)}\n",
    "    y = np.array([1, 0, 1, 1, 0])\n",
    "    return x, y, constant_feature_columns, behavior_feature_columns, behavior_sparse_indicator\n",
    "\n",
    "\n",
    "def make_list(features):\n",
    "    new_feats = {}\n",
    "    for name, value in features.items():\n",
    "        if name in ['y']:\n",
    "            continue\n",
    "        elif (name.find('hist') < 0) and (name != 'pay_score'):\n",
    "            new_feats[name] = value\n",
    "        else:\n",
    "            ini = tf.ones_like(value, dtype=tf.int32)\n",
    "            end = tf.strings.length(value) - 2\n",
    "            value = tf.strings.substr(value, ini, end)\n",
    "            value = tf.strings.split(value, ',').to_tensor()\n",
    "            if name in  ['hist_dense1', 'hist_dense2', 'pay_score']:\n",
    "                value = tf.strings.to_number(value)\n",
    "            else:\n",
    "                value = tf.strings.to_number(value, out_type=tf.int32)\n",
    "            new_feats[name] = value\n",
    "    return new_feats, features['y']\n",
    "\n",
    "\n",
    "def stack_constant_dense(features, label):\n",
    "    new = {feature.name: features[feature.name] for feature in constant_dense_feature_columns}\n",
    "    return tf.concat(list(new.values()), -1)\n",
    "\n",
    "\n",
    "def stack_sequence_dense(features, label):\n",
    "    new = {feature.name: features[feature.name] for feature in varlen_dense_feature_columns}\n",
    "    return tf.stack(list(new.values()), -1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "constant_feature_columns:\n",
    "user (None,), gender(None,), pay_score(None, 3)\n",
    "\n",
    "behavior_feature_columns(L=4):\n",
    "hist_item_id(None, L), hist_cate_id(None, L)\n",
    "hist_dense1(None, L), hist_dense2(None, L)\n",
    "\n",
    "behavior_sparse_indicator: \"item_id\", \"cate_id\"\n",
    "used to indicate sparse features that need to be embedded\n",
    "\n",
    "x: dict, feature array\n",
    "{user: (None, ), gender: (None, ), pay_score: (None, 3),\n",
    " hist_item_id: (None, L), hist_cate_id: (None, L),\n",
    " hist_dense1: (None, L), hist_dense2: (None, L),\n",
    " seq_length: (None,)}\n",
    "\n",
    "L is the max length for all the samples, but some short samples\n",
    " are padded by 0. So, seq_length is used to indicate the actual length of\n",
    " each sample.\n",
    "\n",
    "y: label array (None, )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# toy sequence data\n",
    "x, y, constant_feature_columns, behavior_feature_columns, behavior_sparse_indicator = get_xy_fd()\n",
    "# df = pd.DataFrame()\n",
    "# for name, value in x.items():\n",
    "#     print(name)\n",
    "#     df[name] = value.tolist()\n",
    "# df['y'] = y\n",
    "# df.to_csv('../data/sequence/toy_sequence.csv', index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# fit的时候每个epoch即便没有把dataset消费完\n",
    "# 在下一个epoch会在剩下的里面开始消费，而不是重头开始\n",
    "# shuffle=true保证遍历完dataset后，再次遍历的时候顺序是重新打乱的\n",
    "csv_train_ds = tf.data.experimental.make_csv_dataset(\n",
    "    '../data/sequence/toy_sequence.csv',\n",
    "    batch_size=2,\n",
    "    shuffle_seed=2,\n",
    "    shuffle=True,\n",
    "    ignore_errors=True,)\n",
    "csv_train_adapt_ds = tf.data.experimental.make_csv_dataset(\n",
    "    '../data/sequence/toy_sequence.csv',\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    ignore_errors=True,\n",
    "    num_epochs=1,)\n",
    "\n",
    "# validation的时候，每个epoch即便没有把dataset消费完\n",
    "# 在下一个epoch会重头开始\n",
    "# shuffle=false保证重头开始的时候，顺序依然和上次一样\n",
    "csv_val_ds = tf.data.experimental.make_csv_dataset(\n",
    "    '../data/sequence/toy_sequence.csv',\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    shuffle_seed=2,\n",
    "    num_epochs=1,\n",
    "    ignore_errors=True,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset has only 5 samples, with batch size of 2. So it only has 3 batches.\n",
    "When you restricted the dataset to only iterate over 1 epoch, you can only\n",
    "get 1 epoch of batches(3 batches) even if you specify 5 batches"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "OrderedDict([('user', <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 1])>), ('gender', <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0])>), ('pay_score', <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'[0.1, 0.2, 0.3]', b'[0.2, 0.2, 0.3]'], dtype=object)>), ('hist_item_id', <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'[1, 2, 3, 0]', b'[2, 2, 3, 0]'], dtype=object)>), ('seq_length', <tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 3])>), ('hist_cate_id', <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'[1, 2, 2, 0]', b'[2, 2, 2, 0]'], dtype=object)>), ('hist_dense1', <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'[0.5, 0.1, 0.2, 0.0]', b'[0.7, 0.6, 0.3, 0.0]'], dtype=object)>), ('hist_dense2', <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'[0.2, 0.2, 0.2, 0.0]', b'[0.5, 0.1, 0.1, 0.0]'], dtype=object)>), ('y', <tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 0.], dtype=float32)>)])\n",
      "1\n",
      "OrderedDict([('user', <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 3])>), ('gender', <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 1])>), ('pay_score', <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'[0.3, 0.2, 0.3]', b'[0.4, 0.2, 0.3]'], dtype=object)>), ('hist_item_id', <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'[3, 2, 0, 0]', b'[4, 5, 0, 0]'], dtype=object)>), ('seq_length', <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2])>), ('hist_cate_id', <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'[3, 2, 0, 0]', b'[4, 2, 0, 0]'], dtype=object)>), ('hist_dense1', <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'[0.3, 0.2, 0.0, 0.0]', b'[0.1, 0.1, 0.0, 0.0]'], dtype=object)>), ('hist_dense2', <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'[0.1, 0.2, 0.0, 0.0]', b'[0.4, 0.2, 0.0, 0.0]'], dtype=object)>), ('y', <tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 1.], dtype=float32)>)])\n",
      "2\n",
      "OrderedDict([('user', <tf.Tensor: shape=(1,), dtype=int32, numpy=array([4])>), ('gender', <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>), ('pay_score', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'[0.5, 0.2, 0.3]'], dtype=object)>), ('hist_item_id', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'[5, 1, 2, 0]'], dtype=object)>), ('seq_length', <tf.Tensor: shape=(1,), dtype=int32, numpy=array([3])>), ('hist_cate_id', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'[5, 2, 2, 0]'], dtype=object)>), ('hist_dense1', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'[0.2, 0.1, 0.2, 0.0]'], dtype=object)>), ('hist_dense2', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'[0.3, 0.1, 0.1, 0.0]'], dtype=object)>), ('y', <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>)])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(csv_train_adapt_ds.take(5)):\n",
    "    print(i)\n",
    "    print(batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# sequence features are saved as string in csv. so we need to map it to array\n",
    "csv_train_ds_mapped = csv_train_ds.map(make_list)\n",
    "csv_train_adapt_ds_mapped = csv_train_adapt_ds.map(make_list)\n",
    "csv_val_ds_mapped = csv_val_ds.map(make_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 1])>, 'gender': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0])>, 'pay_score': <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
      "array([[0.1, 0.2, 0.3],\n",
      "       [0.2, 0.2, 0.3]], dtype=float32)>, 'hist_item_id': <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
      "array([[1, 2, 3, 0],\n",
      "       [2, 2, 3, 0]])>, 'seq_length': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 3])>, 'hist_cate_id': <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
      "array([[1, 2, 2, 0],\n",
      "       [2, 2, 2, 0]])>, 'hist_dense1': <tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
      "array([[0.5, 0.1, 0.2, 0. ],\n",
      "       [0.7, 0.6, 0.3, 0. ]], dtype=float32)>, 'hist_dense2': <tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
      "array([[0.2, 0.2, 0.2, 0. ],\n",
      "       [0.5, 0.1, 0.1, 0. ]], dtype=float32)>}\n",
      "tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "{'user': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 3])>, 'gender': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 1])>, 'pay_score': <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
      "array([[0.3, 0.2, 0.3],\n",
      "       [0.4, 0.2, 0.3]], dtype=float32)>, 'hist_item_id': <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
      "array([[3, 2, 0, 0],\n",
      "       [4, 5, 0, 0]])>, 'seq_length': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2])>, 'hist_cate_id': <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
      "array([[3, 2, 0, 0],\n",
      "       [4, 2, 0, 0]])>, 'hist_dense1': <tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
      "array([[0.3, 0.2, 0. , 0. ],\n",
      "       [0.1, 0.1, 0. , 0. ]], dtype=float32)>, 'hist_dense2': <tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
      "array([[0.1, 0.2, 0. , 0. ],\n",
      "       [0.4, 0.2, 0. , 0. ]], dtype=float32)>}\n",
      "tf.Tensor([1. 1.], shape=(2,), dtype=float32)\n",
      "{'user': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([4])>, 'gender': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>, 'pay_score': <tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[0.5, 0.2, 0.3]], dtype=float32)>, 'hist_item_id': <tf.Tensor: shape=(1, 4), dtype=int32, numpy=array([[5, 1, 2, 0]])>, 'seq_length': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([3])>, 'hist_cate_id': <tf.Tensor: shape=(1, 4), dtype=int32, numpy=array([[5, 2, 2, 0]])>, 'hist_dense1': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0.2, 0.1, 0.2, 0. ]], dtype=float32)>, 'hist_dense2': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0.3, 0.1, 0.1, 0. ]], dtype=float32)>}\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for batch, label in csv_val_ds_mapped.take(3):\n",
    "    print(batch)\n",
    "    print(label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tf.Tensor([0 1], shape=(2,), dtype=int32)\n",
      "y tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "x tf.Tensor([2 3], shape=(2,), dtype=int32)\n",
      "y tf.Tensor([1. 1.], shape=(2,), dtype=float32)\n",
      "x tf.Tensor([4], shape=(1,), dtype=int32)\n",
      "y tf.Tensor([0.], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "users = []\n",
    "for feature, label in csv_val_ds_mapped.take(3):\n",
    "    print('x', feature['user'])\n",
    "    print('y', label)\n",
    "    labels.append(label)\n",
    "    users.append(feature['user'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([1., 0., 1., 1., 0.], dtype=float32)>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat(labels, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4])>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat(users, axis=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "features = build_input_features(constant_feature_columns + behavior_feature_columns)\n",
    "constant_dense_feature_columns = list(\n",
    "    filter(lambda x: isinstance(x, DenseFeat), constant_feature_columns) if constant_feature_columns else [])\n",
    "varlen_dense_feature_columns = list(\n",
    "    filter(lambda x: isinstance(x, DenseFeat), behavior_feature_columns) if behavior_feature_columns else [])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For large dataset, normalization of dense features might be done by static op.\n",
    "\n",
    "constant dense features (pay_score-(None, 3)) is extracted out as csv_constant_adapt,\n",
    "and normalization is applied at the last axis.\n",
    "\n",
    "sequence dense features (hist_dense1-(None, L), hist_dense2-(None, L)) are concatenated as csv_constant_adapt\n",
    "(None, L, 2), and normalization is applied at the last axis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "csv_sequence_adapt = csv_train_adapt_ds_mapped.map(stack_sequence_dense)\n",
    "csv_constant_adapt = csv_train_adapt_ds_mapped.map(stack_constant_dense)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.1 0.2 0.3]\n",
      " [0.2 0.2 0.3]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.3 0.2 0.3]\n",
      " [0.4 0.2 0.3]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for batch in csv_constant_adapt.take(2):\n",
    "    print(batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "constant_normalizer = tf.keras.layers.experimental.preprocessing.Normalization(axis=-1)\n",
    "constant_normalizer.adapt(csv_constant_adapt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Variable 'mean:0' shape=(3,) dtype=float32, numpy=array([0.3, 0.2, 0.3], dtype=float32)>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant_normalizer.mean\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.5 0.2]\n",
      "  [0.1 0.2]\n",
      "  [0.2 0.2]\n",
      "  [0.  0. ]]\n",
      "\n",
      " [[0.7 0.5]\n",
      "  [0.6 0.1]\n",
      "  [0.3 0.1]\n",
      "  [0.  0. ]]], shape=(2, 4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[0.3 0.1]\n",
      "  [0.2 0.2]\n",
      "  [0.  0. ]\n",
      "  [0.  0. ]]\n",
      "\n",
      " [[0.1 0.4]\n",
      "  [0.1 0.2]\n",
      "  [0.  0. ]\n",
      "  [0.  0. ]]], shape=(2, 4, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for batch in csv_sequence_adapt.take(2):\n",
    "    print(batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "sequence_normalizer = tf.keras.layers.experimental.preprocessing.Normalization(axis=-1)\n",
    "sequence_normalizer.adapt(csv_sequence_adapt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Variable 'mean:0' shape=(2,) dtype=float32, numpy=array([0.18 , 0.135], dtype=float32)>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_normalizer.mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "model = AttentionalPooling(constant_feature_columns, behavior_feature_columns, behavior_sparse_indicator,\n",
    "                           sequence_dense_normalizer=sequence_normalizer,\n",
    "                           constant_dense_normalizer=constant_normalizer,\n",
    "                           dnn_hidden_units=[4, 4], dnn_dropout=0.6)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, clipvalue=1.0)\n",
    "model.compile(optimizer, \"binary_crossentropy\")\n",
    "# print(model.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "      1/Unknown - 0s 0s/step - loss: 8.2119WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0157s). Check your callbacks.\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 9.7543 - val_loss: 12.0679\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 9.7541 - val_loss: 12.0677\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 9.7539 - val_loss: 12.0676\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 9.7538 - val_loss: 12.0674\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 9.7536 - val_loss: 12.0673\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\python3.6_tf2\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(csv_val_ds_mapped,\n",
    "                    epochs=5,\n",
    "                    validation_data=csv_val_ds_mapped,\n",
    "                    validation_steps=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.]], dtype=float32)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(csv_val_ds_mapped, steps=10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}